{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-27T17:39:47.800853Z",
     "iopub.status.busy": "2025-12-27T17:39:47.800545Z",
     "iopub.status.idle": "2025-12-27T17:40:48.754374Z",
     "shell.execute_reply": "2025-12-27T17:40:48.753483Z",
     "shell.execute_reply.started": "2025-12-27T17:39:47.800821Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m157.1/157.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m102.8/102.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m484.9/484.9 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m343.7/343.7 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "xmanager 0.7.1 requires sqlalchemy==1.2.19, but you have sqlalchemy 2.0.45 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m68.6/68.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m444.8/444.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# CELL 1: Install Dependencies\n",
    "# ================================================================================\n",
    "!pip install -q langgraph langchain langchain-community langchain-huggingface\n",
    "!pip install -q transformers torch torchvision pillow\n",
    "!pip install -q faiss-cpu sentence-transformers\n",
    "!pip install -q pandas numpy matplotlib seaborn gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================================\n",
    "# FASHION MULTI-AGENT AI SYSTEM - FIXED IMAGE SEARCH\n",
    "# ================================================================================\n",
    "# Save this as: fashion_assistant_fixed_complete.ipynb\n",
    "# Run cells sequentially for best results\n",
    "# ================================================================================\n",
    "\n",
    "# CELL 1: System Info\n",
    "# ================================================================================\n",
    "print(\"=\"*80)\n",
    "print(\"üé® FASHION MULTI-AGENT AI SYSTEM - FIXED IMAGE SEARCH\")\n",
    "print(\"=\"*80)\n",
    "print(\"Starting initialization...\")\n",
    "\n",
    "# CELL 2: Imports\n",
    "# ================================================================================\n",
    "import os, json, warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from typing import TypedDict, Annotated, List, Optional, Dict, Union\n",
    "import operator\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM, CLIPProcessor, CLIPModel\n",
    "import torch\n",
    "import faiss\n",
    "import gradio as gr\n",
    "\n",
    "# Gemini imports\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "print(\"‚úÖ All imports loaded successfully\")\n",
    "\n",
    "# ================================================================================\n",
    "# CELL 3: CONFIGURATION WITH DYNAMIC VOCABULARY\n",
    "# ================================================================================\n",
    "\n",
    "class Config:\n",
    "    # Paths\n",
    "    DATA_PATH = \"/kaggle/input/fashion-product-images-small\"\n",
    "    IMAGES_PATH = os.path.join(DATA_PATH, \"images\")\n",
    "    STYLES_CSV = os.path.join(DATA_PATH, \"styles.csv\")\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # Models\n",
    "    CLASSIFIER_MODEL = \"google/flan-t5-large\"\n",
    "    GENERATOR_MODEL = \"google/flan-t5-base\"\n",
    "    CLIP_MODEL = \"patrickjohncyh/fashion-clip\"\n",
    "    \n",
    "    # LLM Settings\n",
    "    CLASSIFIER_TEMP = 0.1\n",
    "    GENERATOR_TEMP = 0.7\n",
    "    MAX_TOKENS_CLASSIFIER = 20\n",
    "    MAX_TOKENS_GENERATOR = 150\n",
    "    \n",
    "    # Image Validation Thresholds\n",
    "    FASHION_SCORE_THRESHOLD = 0.20\n",
    "    NON_FASHION_THRESHOLD = 0.30\n",
    "    HIGH_CONFIDENCE_THRESHOLD = 0.70\n",
    "    SIMILARITY_WARNING_THRESHOLD = 0.25\n",
    "    \n",
    "    # Text Intent Classification\n",
    "    TEXT_FASHION_THRESHOLD = 0.3\n",
    "    TEXT_SEARCH_THRESHOLD = 0.5\n",
    "    \n",
    "    # FIXED: Hybrid Search Weights\n",
    "    TEXT_WEIGHT = 0.30  # 30% for text when both present\n",
    "    IMAGE_WEIGHT = 0.70  # 70% for image when both present\n",
    "    IMAGE_ONLY_WEIGHT = 1.0  # 100% for image-only search\n",
    "    TEXT_ONLY_WEIGHT = 1.0  # 100% for text-only search\n",
    "    \n",
    "    # Search Settings\n",
    "    FAISS_MAX_ITEMS = 44419\n",
    "    SEARCH_DEFAULT_K = 5\n",
    "    INDEX_BATCH_SIZE = 1000\n",
    "    \n",
    "    # Gradio Settings\n",
    "    GRADIO_PORT = 7860\n",
    "    GRADIO_SHARE = True\n",
    "    GRADIO_DEBUG = True\n",
    "    \n",
    "    # Dynamic Vocabulary (populated at runtime)\n",
    "    DYNAMIC_FASHION_ITEMS = set()\n",
    "    DYNAMIC_COLORS = set()\n",
    "    DYNAMIC_BRANDS = set()\n",
    "    DYNAMIC_GENDERS = set()  # NEW: Track available genders\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# ================================================================================\n",
    "# GEMINI API CONFIGURATION\n",
    "# ================================================================================\n",
    "client = genai.Client(api_key=\"AIzaSyD4qzcdDXV0BzPoTvcNefGDCHdmjA4KFps\")\n",
    "MODEL = \"gemini-2.5-flash-lite\"\n",
    "\n",
    "print(f\"‚úÖ Config Loaded\")\n",
    "print(f\"   Device: {config.DEVICE}\")\n",
    "print(f\"   Image-Only Search: {config.IMAGE_ONLY_WEIGHT*100}% image\")\n",
    "print(f\"   Text-Only Search: {config.TEXT_ONLY_WEIGHT*100}% text\")\n",
    "print(f\"   Hybrid Search: {config.TEXT_WEIGHT*100}% text, {config.IMAGE_WEIGHT*100}% image\")\n",
    "print(f\"‚úÖ Gemini API configured: {MODEL}\")\n",
    "\n",
    "# CELL 4: Initialize LLMs\n",
    "# ================================================================================\n",
    "def safe_invoke(llm, prompt: str) -> str:\n",
    "    try:\n",
    "        return str(llm.invoke(prompt)).strip().replace(\"</s>\", \"\")\n",
    "    except:\n",
    "        return \"ERROR\"\n",
    "\n",
    "def initialize_llms():\n",
    "    print(\"\\nüîß Initializing LLMs...\")\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(config.CLASSIFIER_MODEL)\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(config.CLASSIFIER_MODEL).to(config.DEVICE)\n",
    "        pipe = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, \n",
    "                       device=0 if config.DEVICE==\"cuda\" else -1, \n",
    "                       max_new_tokens=config.MAX_TOKENS_CLASSIFIER, temperature=config.CLASSIFIER_TEMP)\n",
    "        classifier_llm = HuggingFacePipeline(pipeline=pipe)\n",
    "        print(f\"‚úÖ Classifier: {config.CLASSIFIER_MODEL}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Classifier failed: {e}\")\n",
    "        classifier_llm = None\n",
    "    \n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(config.GENERATOR_MODEL)\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(config.GENERATOR_MODEL).to(config.DEVICE)\n",
    "        pipe = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer,\n",
    "                       device=0 if config.DEVICE==\"cuda\" else -1,\n",
    "                       max_new_tokens=config.MAX_TOKENS_GENERATOR, temperature=config.GENERATOR_TEMP)\n",
    "        generator_llm = HuggingFacePipeline(pipeline=pipe)\n",
    "        print(f\"‚úÖ Generator: {config.GENERATOR_MODEL}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Generator failed: {e}\")\n",
    "        generator_llm = None\n",
    "    \n",
    "    return classifier_llm, generator_llm\n",
    "\n",
    "classifier_llm, generator_llm = initialize_llms()\n",
    "\n",
    "# ================================================================================\n",
    "# CELL 5: LOAD DATASET + BUILD DYNAMIC VOCABULARY\n",
    "# ================================================================================\n",
    "\n",
    "print(\"\\nüìä Loading dataset and building dynamic vocabulary...\")\n",
    "df = pd.read_csv(config.STYLES_CSV, on_bad_lines='skip')\n",
    "\n",
    "# Build image paths\n",
    "df['image_path'] = df.apply(\n",
    "    lambda r: os.path.join(config.IMAGES_PATH, f\"{r['id']}.jpg\") \n",
    "    if os.path.exists(os.path.join(config.IMAGES_PATH, f\"{r['id']}.jpg\")) else None, \n",
    "    axis=1\n",
    ")\n",
    "df['image_id'] = df['id'].astype(str)\n",
    "df_with_images = df[df['image_path'].notna()].copy()\n",
    "\n",
    "def build_dynamic_vocabulary(dataframe):\n",
    "    \"\"\"Extracts fashion keywords from dataset columns\"\"\"\n",
    "    print(\"\\nüîß Building dynamic vocabulary from dataset...\")\n",
    "    \n",
    "    # Extract unique article types (items)\n",
    "    if 'articleType' in dataframe.columns:\n",
    "        items = dataframe['articleType'].dropna().str.lower().str.strip().unique()\n",
    "        config.DYNAMIC_FASHION_ITEMS.update(items)\n",
    "        print(f\"   ‚úì {len(items)} article types detected\")\n",
    "    \n",
    "    # Extract unique colors\n",
    "    if 'baseColour' in dataframe.columns:\n",
    "        colors = dataframe['baseColour'].dropna().str.lower().str.strip().unique()\n",
    "        config.DYNAMIC_COLORS.update(colors)\n",
    "        print(f\"   ‚úì {len(colors)} colors detected\")\n",
    "    \n",
    "    # Extract unique brands\n",
    "    if 'brandName' in dataframe.columns:\n",
    "        brands = dataframe['brandName'].dropna().str.lower().str.strip().unique()\n",
    "        config.DYNAMIC_BRANDS.update(brands)\n",
    "        print(f\"   ‚úì {len(brands)} brands detected\")\n",
    "    \n",
    "    if 'productDisplayName' in dataframe.columns:\n",
    "        products = dataframe['productDisplayName'].dropna().str.lower().str.strip().unique()\n",
    "        config.DYNAMIC_BRANDS.update(products)\n",
    "        print(f\"   ‚úì {len(products)} product names detected\")\n",
    "    \n",
    "    # NEW: Extract unique genders\n",
    "    if 'gender' in dataframe.columns:\n",
    "        genders = dataframe['gender'].dropna().str.lower().str.strip().unique()\n",
    "        config.DYNAMIC_GENDERS.update(genders)\n",
    "        print(f\"   ‚úì {len(genders)} genders detected: {', '.join(genders)}\")\n",
    "    \n",
    "    # Sample output\n",
    "    sample_items = list(config.DYNAMIC_FASHION_ITEMS)[:10]\n",
    "    sample_colors = list(config.DYNAMIC_COLORS)[:10]\n",
    "    print(f\"\\n   Sample items: {', '.join(sample_items)}\")\n",
    "    print(f\"   Sample colors: {', '.join(sample_colors)}\")\n",
    "\n",
    "build_dynamic_vocabulary(df_with_images)\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset: {df.shape[0]} rows, {len(df_with_images)} valid images\")\n",
    "print(f\"‚úÖ Vocabulary: {len(config.DYNAMIC_FASHION_ITEMS)} items, {len(config.DYNAMIC_COLORS)} colors\")\n",
    "\n",
    "# CELL 6: Load CLIP\n",
    "# ================================================================================\n",
    "print(\"\\nüé® Loading Fashion-CLIP...\")\n",
    "clip_model = CLIPModel.from_pretrained(config.CLIP_MODEL).to(config.DEVICE)\n",
    "clip_processor = CLIPProcessor.from_pretrained(config.CLIP_MODEL)\n",
    "print(\"‚úÖ Fashion-CLIP loaded\")\n",
    "\n",
    "# ================================================================================\n",
    "# CELL 7: STATE DEFINITION WITH IMAGE EMBEDDING\n",
    "# ================================================================================\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    user_input: str\n",
    "    image_input: Optional[str]\n",
    "    image_embedding: Optional[np.ndarray]  # NEW: Store image embedding\n",
    "    is_fashion_image: Optional[bool]\n",
    "    image_validation_reason: Optional[str]\n",
    "    image_description: Optional[str]\n",
    "    text_query: Optional[str]\n",
    "    intent: Optional[str]\n",
    "    intent_class: Optional[str]\n",
    "    messages: Annotated[List[str], operator.add]\n",
    "    final_response: Optional[str]\n",
    "    next_agent: Optional[str]\n",
    "    debug_info: Optional[dict]\n",
    "    search_queries: Optional[List[str]]\n",
    "    search_results_data: Optional[List[dict]]\n",
    "    query_categories: Optional[List[str]]\n",
    "    intent_type: Optional[str]\n",
    "    search_mode: Optional[str]  # NEW: 'image_only', 'text_only', 'hybrid'\n",
    "    detected_gender: Optional[str]  # NEW: Track detected gender\n",
    "    gender_source: Optional[str]  # NEW: Track how gender was detected (LLM/rule/both/none)\n",
    "\n",
    "def get_image_embedding(image: Image.Image) -> np.ndarray:\n",
    "    inputs = clip_processor(images=image, return_tensors=\"pt\").to(config.DEVICE)\n",
    "    with torch.no_grad():\n",
    "        features = clip_model.get_image_features(**inputs)\n",
    "        embedding = features.cpu().numpy()[0]\n",
    "        embedding = embedding / np.linalg.norm(embedding)\n",
    "    return embedding.astype('float32')\n",
    "\n",
    "def get_text_embedding(text: str) -> np.ndarray:\n",
    "    inputs = clip_processor(text=[text], return_tensors=\"pt\", padding=True).to(config.DEVICE)\n",
    "    with torch.no_grad():\n",
    "        features = clip_model.get_text_features(**inputs)\n",
    "        embedding = features.cpu().numpy()[0]\n",
    "        embedding = embedding / np.linalg.norm(embedding)\n",
    "    return embedding.astype('float32')\n",
    "\n",
    "# ================================================================================\n",
    "# CELL 8: AGENT FUNCTIONS - IMAGE VALIDATOR & DESCRIPTION\n",
    "# ================================================================================\n",
    "\n",
    "def image_fashion_validator_agent(state: AgentState) -> AgentState:\n",
    "    \"\"\"Validates if uploaded image is fashion-related and extracts embedding\"\"\"\n",
    "    if not state.get('image_input'):\n",
    "        state['is_fashion_image'] = None\n",
    "        state['image_embedding'] = None\n",
    "        state['text_query'] = state.get('user_input', '').strip() or \"hello\"\n",
    "        state['messages'].append(\"‚≠ê No image - text mode\")\n",
    "        state['next_agent'] = 'intent_classifier'\n",
    "        return state\n",
    "    \n",
    "    try:\n",
    "        image = Image.open(state['image_input']).convert('RGB')\n",
    "        \n",
    "        # EXTRACT IMAGE EMBEDDING IMMEDIATELY\n",
    "        img_embedding = get_image_embedding(image)\n",
    "        state['image_embedding'] = img_embedding\n",
    "        \n",
    "        inputs = clip_processor(images=image, return_tensors=\"pt\").to(config.DEVICE)\n",
    "        \n",
    "        # Dynamic fashion categories from dataset\n",
    "        fashion_cats = list(config.DYNAMIC_FASHION_ITEMS)[:30]\n",
    "        generic_fashion = [\"clothing\", \"fashion\", \"apparel\", \"footwear\", \"accessory\", \n",
    "                          \"garment\", \"outfit\", \"attire\", \"wear\"]\n",
    "        fashion_cats = list(set(fashion_cats + generic_fashion))\n",
    "        \n",
    "        # Non-fashion categories\n",
    "        non_fashion_cats = [\"animal\", \"car\", \"vehicle\", \"building\", \"architecture\", \n",
    "                           \"food\", \"meal\", \"landscape\", \"nature\", \"plant\", \"tree\",\n",
    "                           \"electronics\", \"furniture\", \"tool\", \"instrument\"]\n",
    "        \n",
    "        all_cats = fashion_cats + non_fashion_cats\n",
    "        \n",
    "        # CLIP Classification\n",
    "        text_inputs = clip_processor(text=all_cats, return_tensors=\"pt\", padding=True).to(config.DEVICE)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            img_feat = clip_model.get_image_features(**inputs)\n",
    "            txt_feat = clip_model.get_text_features(**text_inputs)\n",
    "            sim = (img_feat @ txt_feat.T).softmax(dim=-1)\n",
    "            top_idx = sim[0].topk(10).indices.cpu().numpy()\n",
    "            top_scores = sim[0].topk(10).values.cpu().numpy()\n",
    "            top_cats = [all_cats[i] for i in top_idx]\n",
    "        \n",
    "        # Calculate fashion vs non-fashion scores\n",
    "        f_score = sum(float(top_scores[i]) for i, c in enumerate(top_cats) if c in fashion_cats)\n",
    "        nf_score = sum(float(top_scores[i]) for i, c in enumerate(top_cats) if c in non_fashion_cats)\n",
    "        \n",
    "        is_fashion = f_score > config.FASHION_SCORE_THRESHOLD and f_score > nf_score\n",
    "        \n",
    "        top_3_cats = [f\"{top_cats[i]} ({top_scores[i]:.2f})\" for i in range(min(3, len(top_cats)))]\n",
    "        reason = f\"F={f_score:.2f}, NF={nf_score:.2f} | Top: {', '.join(top_3_cats)}\"\n",
    "        \n",
    "        state['is_fashion_image'] = is_fashion\n",
    "        state['image_validation_reason'] = reason\n",
    "        state['debug_info'] = {\n",
    "            'fashion_score': float(f_score),\n",
    "            'non_fashion_score': float(nf_score),\n",
    "            'top_predictions': top_3_cats,\n",
    "            'fashion_categories_used': len(fashion_cats),\n",
    "            'dynamic_categories': fashion_cats[:10],\n",
    "            'image_embedding_extracted': True\n",
    "        }\n",
    "        \n",
    "        state['messages'].append(\n",
    "            f\"{'‚úÖ Fashion image' if is_fashion else '‚ùå Non-fashion'}: {reason}\"\n",
    "        )\n",
    "        state['next_agent'] = 'image_to_description' if is_fashion else 'non_relevant_image_agent'\n",
    "        \n",
    "    except Exception as e:\n",
    "        state['is_fashion_image'] = False\n",
    "        state['image_embedding'] = None\n",
    "        state['image_validation_reason'] = f\"Error: {str(e)}\"\n",
    "        state['messages'].append(f\"‚ö†Ô∏è Image error: {str(e)[:50]}\")\n",
    "        state['next_agent'] = 'non_relevant_image_agent'\n",
    "    \n",
    "    return state\n",
    "\n",
    "def image_to_description_agent(state: AgentState) -> AgentState:\n",
    "    \"\"\"Converts fashion image to text description (lightweight for context)\"\"\"\n",
    "    user_text = state.get('user_input', '').strip()\n",
    "    \n",
    "    if state.get('image_input') and state.get('is_fashion_image'):\n",
    "        try:\n",
    "            image = Image.open(state['image_input']).convert('RGB')\n",
    "            inputs = clip_processor(images=image, return_tensors=\"pt\").to(config.DEVICE)\n",
    "            \n",
    "            # Get top attributes from dataset vocabulary\n",
    "            sample_items = list(config.DYNAMIC_FASHION_ITEMS)[:50]\n",
    "            sample_colors = list(config.DYNAMIC_COLORS)[:30]\n",
    "            \n",
    "            attrs = sample_items + sample_colors + [\"casual\", \"formal\", \"summer\", \"winter\"]\n",
    "            text_inputs = clip_processor(text=attrs, return_tensors=\"pt\", padding=True).to(config.DEVICE)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                img_feat = clip_model.get_image_features(**inputs)\n",
    "                txt_feat = clip_model.get_text_features(**text_inputs)\n",
    "                sim = (img_feat @ txt_feat.T).softmax(dim=-1)\n",
    "                top_idx = sim[0].topk(5).indices.cpu().numpy()\n",
    "                detected = [attrs[i] for i in top_idx]\n",
    "            \n",
    "            # Build richer description\n",
    "            image_desc = \" \".join(detected[:5])\n",
    "            state['image_description'] = image_desc\n",
    "            \n",
    "            if user_text:\n",
    "                state['text_query'] = user_text\n",
    "                state['messages'].append(f\"üìù Text: '{user_text}' + Image: {image_desc}\")\n",
    "            else:\n",
    "                state['text_query'] = image_desc  # Fallback description\n",
    "                state['messages'].append(f\"üì∏ Image query: {image_desc}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            state['text_query'] = user_text or \"fashion items\"\n",
    "            state['messages'].append(f\"‚ö†Ô∏è Image desc error\")\n",
    "    else:\n",
    "        state['text_query'] = user_text or \"hello\"\n",
    "        state['messages'].append(f\"üí¨ Text mode\")\n",
    "    \n",
    "    state['next_agent'] = 'intent_classifier'\n",
    "    return state\n",
    "\n",
    "def non_relevant_image_agent(state: AgentState) -> AgentState:\n",
    "    \"\"\"Handles non-fashion images\"\"\"\n",
    "    reason = state.get('image_validation_reason', 'Image is not fashion-related')\n",
    "    state['final_response'] = f\"üì∏ **Non-Fashion Image Detected**\\n\\n{reason}\\n\\nPlease upload fashion items (clothing, shoes, accessories) for search!\"\n",
    "    state['next_agent'] = 'end'\n",
    "    state['messages'].append(\"‚ùå Ended: Non-fashion image\")\n",
    "    return state\n",
    "\n",
    "# ================================================================================\n",
    "# CELL 9: INTENT CLASSIFIER\n",
    "# ================================================================================\n",
    "\n",
    "def intent_classifier_agent(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    ENHANCED HYBRID APPROACH: Fast keyword check + Dynamic LLM verification\n",
    "    \"\"\"\n",
    "    query = state.get('text_query', '').lower().strip()\n",
    "    \n",
    "    # Greeting detection\n",
    "    greeting_patterns = [\n",
    "        \"hi\", \"hello\", \"hey\", \"good morning\", \"good evening\", \"good afternoon\",\n",
    "        \"what can you\", \"who are\", \"what do you do\", \"help me\", \"greetings\"\n",
    "    ]\n",
    "    \n",
    "    if any(query.startswith(pattern) for pattern in greeting_patterns):\n",
    "        state['intent'] = 'welcome'\n",
    "        state['next_agent'] = 'welcome_agent'\n",
    "        state['messages'].append(f\"üéØ Welcome (instant detection)\")\n",
    "        return state\n",
    "    \n",
    "    # Quick keyword scan\n",
    "    matched_items = []\n",
    "    matched_colors = []\n",
    "    matched_brands = []\n",
    "    \n",
    "    for item in config.DYNAMIC_FASHION_ITEMS:\n",
    "        if item in query:\n",
    "            matched_items.append(item)\n",
    "    \n",
    "    for color in config.DYNAMIC_COLORS:\n",
    "        if color in query:\n",
    "            matched_colors.append(color)\n",
    "    \n",
    "    for brand in config.DYNAMIC_BRANDS:\n",
    "        if brand in query:\n",
    "            matched_brands.append(brand)\n",
    "    \n",
    "    fashion_keywords = [\n",
    "        \"wear\", \"outfit\", \"style\", \"look\", \"trend\", \"collection\", \"season\",\n",
    "        \"material\", \"fabric\", \"pattern\", \"design\", \"size\", \"fit\", \"casual\",\n",
    "        \"formal\", \"party\", \"wedding\", \"sport\", \"summer\", \"winter\", \"vintage\"\n",
    "    ]\n",
    "    matched_keywords = [kw for kw in fashion_keywords if kw in query]\n",
    "    \n",
    "    has_fashion_image = state.get('is_fashion_image') == True\n",
    "    \n",
    "    has_fashion_signals = (\n",
    "        len(matched_items) >= 1 or\n",
    "        has_fashion_image or\n",
    "        len(matched_colors) >= 1 or\n",
    "        len(matched_brands) >= 1 or\n",
    "        len(matched_keywords) >= 1\n",
    "    )\n",
    "    \n",
    "    if has_fashion_signals:\n",
    "        state['intent'] = 'relevant_fashion'\n",
    "        state['next_agent'] = 'fashion_classifier'\n",
    "        \n",
    "        signals = []\n",
    "        if matched_items:\n",
    "            signals.append(f\"items={matched_items[:2]}\")\n",
    "        if matched_colors:\n",
    "            signals.append(f\"colors={matched_colors[:2]}\")\n",
    "        if matched_brands:\n",
    "            signals.append(f\"brands={matched_brands[:1]}\")\n",
    "        if matched_keywords:\n",
    "            signals.append(f\"keywords={matched_keywords[:2]}\")\n",
    "        \n",
    "        state['messages'].append(f\"üéØ Fashion detected ({', '.join(signals)})\")\n",
    "    \n",
    "    elif classifier_llm:\n",
    "        # Dynamic LLM verification\n",
    "        sample_items = list(config.DYNAMIC_FASHION_ITEMS)[:20]\n",
    "        sample_colors = list(config.DYNAMIC_COLORS)[:15]\n",
    "        sample_brands = list(config.DYNAMIC_BRANDS)[:10]\n",
    "        \n",
    "        categories_text = \"\"\n",
    "        \n",
    "        if sample_items:\n",
    "            categories_text += f\"\\n- Fashion Items: {', '.join(sample_items)}\"\n",
    "        \n",
    "        if sample_colors:\n",
    "            categories_text += f\"\\n- Colors: {', '.join(sample_colors)}\"\n",
    "        \n",
    "        if sample_brands:\n",
    "            categories_text += f\"\\n- Brands: {', '.join(sample_brands)}\"\n",
    "        \n",
    "        categories_text += f\"\\n- Fashion Keywords: shopping, style, outfit, wear, look, trend, material, fabric, size, fit\"\n",
    "        \n",
    "        llm_prompt = f\"\"\"Is this query related to fashion?\n",
    "\n",
    "Query: \"{query}\"\n",
    "\n",
    "Fashion includes:{categories_text}\n",
    "\n",
    "Answer ONLY with YES or NO.\n",
    "YES if the query is about ANY of the above fashion categories.\n",
    "NO if it's about other topics (food, animals, cars, sports events, general questions).\n",
    "\n",
    "Answer:\"\"\"\n",
    "        \n",
    "        try:\n",
    "            llm_response = safe_invoke(classifier_llm, llm_prompt).strip().upper()\n",
    "            is_fashion = \"YES\" in llm_response\n",
    "            \n",
    "            if is_fashion:\n",
    "                state['intent'] = 'relevant_fashion'\n",
    "                state['next_agent'] = 'fashion_classifier'\n",
    "                state['messages'].append(f\"üéØ Fashion (LLM verified: {llm_response})\")\n",
    "            else:\n",
    "                state['intent'] = 'non_relevant'\n",
    "                state['next_agent'] = 'non_relevant_agent'\n",
    "                state['messages'].append(f\"üéØ Non-fashion (LLM: {llm_response})\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            state['intent'] = 'non_relevant'\n",
    "            state['next_agent'] = 'non_relevant_agent'\n",
    "            state['messages'].append(f\"üéØ Non-fashion (LLM error)\")\n",
    "    \n",
    "    else:\n",
    "        state['intent'] = 'non_relevant'\n",
    "        state['next_agent'] = 'non_relevant_agent'\n",
    "        state['messages'].append(f\"üéØ Non-fashion (no signals, no LLM)\")\n",
    "    \n",
    "    state['debug_info'] = state.get('debug_info', {})\n",
    "    state['debug_info'].update({\n",
    "        'matched_items': matched_items,\n",
    "        'matched_colors': matched_colors,\n",
    "        'matched_brands': matched_brands,\n",
    "        'matched_keywords': matched_keywords,\n",
    "        'has_fashion_image': has_fashion_image,\n",
    "        'vocabulary_size': len(config.DYNAMIC_FASHION_ITEMS),\n",
    "        'total_signals': len(matched_items) + len(matched_colors) + len(matched_brands) + len(matched_keywords)\n",
    "    })\n",
    "    \n",
    "    return state\n",
    "\n",
    "def welcome_agent(state: AgentState) -> AgentState:\n",
    "    \"\"\"Welcomes user and provides examples\"\"\"\n",
    "    state['final_response'] = \"\"\"üëã **Welcome to Smart Fashion Search!**\n",
    "\n",
    "**What I can do:**\n",
    "\n",
    "üîç **Direct Search:**\n",
    "- \"blue jeans\" ‚Üí Find blue jeans\n",
    "- \"black dress\" ‚Üí Find black dresses\n",
    "\n",
    "üé® **Matching Items:**\n",
    "- \"black shirt for blue pants\" ‚Üí Find matching shirts\n",
    "- Upload pants image + \"white shirt\" ‚Üí Find complementary shirts\n",
    "\n",
    "üéØ **Complete Outfits:**\n",
    "- \"wedding outfit\" ‚Üí Get tops, bottoms, shoes, accessories\n",
    "- \"casual summer look\" ‚Üí Full outfit suggestions\n",
    "\n",
    "üì∏ **Image Search:**\n",
    "- Upload fashion image ‚Üí Find similar items (uses visual similarity)\n",
    "\n",
    "**Try these examples to get started!**\"\"\"\n",
    "    state['next_agent'] = 'end'\n",
    "    state['messages'].append(\"‚úÖ Ended: Welcome message\")\n",
    "    return state\n",
    "\n",
    "def non_relevant_agent(state: AgentState) -> AgentState:\n",
    "    \"\"\"Handles non-fashion text queries\"\"\"\n",
    "    state['final_response'] = \"üòä **I specialize in fashion search!**\\n\\n**Try:**\\n‚Ä¢ 'blue shirt'\\n‚Ä¢ 'black jeans for white shirt'\\n‚Ä¢ 'wedding outfit'\\n‚Ä¢ Upload a fashion image\"\n",
    "    state['next_agent'] = 'end'\n",
    "    state['messages'].append(\"‚ùå Ended: Non-fashion query\")\n",
    "    return state\n",
    "\n",
    "# ================================================================================\n",
    "# CELL 10: FIXED SMART QUERY UNDERSTANDING AGENT WITH GENDER DETECTION\n",
    "# ================================================================================\n",
    "\n",
    "def smart_query_understanding_agent(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    ENHANCED: Gender-aware query understanding\n",
    "    - Detects gender from text (rule-based + LLM)\n",
    "    - If no gender specified ‚Üí searches both men and women\n",
    "    - If gender specified ‚Üí searches only that gender\n",
    "    \"\"\"\n",
    "    \n",
    "    query = state.get('text_query', '').strip().lower()\n",
    "    has_image = state.get('is_fashion_image') == True\n",
    "    image_desc = state.get('image_description', '')\n",
    "    debug_info = state.get('debug_info', {})\n",
    "    \n",
    "    matched_items = debug_info.get('matched_items', [])\n",
    "    matched_colors = debug_info.get('matched_colors', [])\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 1: GENDER DETECTION (Rule-based + LLM)\n",
    "    # ========================================================================\n",
    "    \n",
    "    detected_gender_rule = None\n",
    "    detected_gender_llm = None\n",
    "    final_gender = None\n",
    "    gender_source = \"none\"\n",
    "    \n",
    "    # Rule-based gender detection\n",
    "    male_keywords = ['men', 'man', 'male', 'guy', 'boy', 'gentleman', 'his', 'he', 'him']\n",
    "    female_keywords = ['women', 'woman', 'female', 'girl', 'lady', 'her', 'she']\n",
    "    \n",
    "    query_words = query.split()\n",
    "    has_male = any(kw in query_words for kw in male_keywords)\n",
    "    has_female = any(kw in query_words for kw in female_keywords)\n",
    "    \n",
    "    if has_male and not has_female:\n",
    "        detected_gender_rule = \"men\"\n",
    "        state['messages'].append(f\"üöπ Rule-based: Detected MALE gender\")\n",
    "    elif has_female and not has_male:\n",
    "        detected_gender_rule = \"women\"\n",
    "        state['messages'].append(f\"üö∫ Rule-based: Detected FEMALE gender\")\n",
    "    elif has_male and has_female:\n",
    "        detected_gender_rule = \"both\"\n",
    "        state['messages'].append(f\"‚öß Rule-based: Both genders mentioned\")\n",
    "    else:\n",
    "        state['messages'].append(f\"‚ö™ Rule-based: No gender detected\")\n",
    "    \n",
    "    # LLM-based gender detection (only if needed)\n",
    "    if classifier_llm and detected_gender_rule is None:\n",
    "        available_genders = list(config.DYNAMIC_GENDERS)\n",
    "        \n",
    "        llm_gender_prompt = f\"\"\"Analyze this fashion query and determine the target gender.\n",
    "\n",
    "Query: \"{query}\"\n",
    "\n",
    "Available genders in our catalog: {', '.join(available_genders)}\n",
    "\n",
    "Instructions:\n",
    "- If the query mentions men/man/male/boy/his/he/him ‚Üí Answer: MEN\n",
    "- If the query mentions women/woman/female/girl/her/she ‚Üí Answer: WOMEN  \n",
    "- If the query mentions both genders ‚Üí Answer: BOTH\n",
    "- If NO gender is mentioned ‚Üí Answer: BOTH (show both genders)\n",
    "\n",
    "Answer with ONLY ONE WORD: MEN, WOMEN, or BOTH\"\"\"\n",
    "\n",
    "        try:\n",
    "            llm_response = safe_invoke(classifier_llm, llm_gender_prompt).strip().upper()\n",
    "            \n",
    "            if \"MEN\" in llm_response and \"WOMEN\" not in llm_response:\n",
    "                detected_gender_llm = \"men\"\n",
    "                state['messages'].append(f\"ü§ñ LLM: Detected MALE gender\")\n",
    "            elif \"WOMEN\" in llm_response:\n",
    "                detected_gender_llm = \"women\"\n",
    "                state['messages'].append(f\"ü§ñ LLM: Detected FEMALE gender\")\n",
    "            elif \"BOTH\" in llm_response:\n",
    "                detected_gender_llm = \"both\"\n",
    "                state['messages'].append(f\"ü§ñ LLM: Both genders\")\n",
    "            else:\n",
    "                state['messages'].append(f\"ü§ñ LLM: Unclear response ‚Üí defaulting to BOTH\")\n",
    "                detected_gender_llm = \"both\"\n",
    "        \n",
    "        except Exception as e:\n",
    "            state['messages'].append(f\"‚ö†Ô∏è LLM gender detection failed\")\n",
    "            detected_gender_llm = None\n",
    "    \n",
    "    # Combine rule-based + LLM results\n",
    "    if detected_gender_rule and detected_gender_llm:\n",
    "        # Both detected - prefer rule-based if they match, otherwise use rule\n",
    "        if detected_gender_rule == detected_gender_llm:\n",
    "            final_gender = detected_gender_rule\n",
    "            gender_source = \"both_agree\"\n",
    "            state['messages'].append(f\"‚úÖ Gender confirmed: {final_gender.upper()} (rule + LLM agree)\")\n",
    "        else:\n",
    "            final_gender = detected_gender_rule  # Prefer explicit keywords\n",
    "            gender_source = \"rule_priority\"\n",
    "            state['messages'].append(f\"‚öñÔ∏è Gender conflict: Using rule-based ({final_gender.upper()})\")\n",
    "    \n",
    "    elif detected_gender_rule:\n",
    "        final_gender = detected_gender_rule\n",
    "        gender_source = \"rule_only\"\n",
    "        state['messages'].append(f\"üìè Gender: {final_gender.upper()} (rule-based only)\")\n",
    "    \n",
    "    elif detected_gender_llm:\n",
    "        final_gender = detected_gender_llm\n",
    "        gender_source = \"llm_only\"\n",
    "        state['messages'].append(f\"ü§ñ Gender: {final_gender.upper()} (LLM only)\")\n",
    "    \n",
    "    else:\n",
    "        final_gender = \"both\"\n",
    "        gender_source = \"default_both\"\n",
    "        state['messages'].append(f\"üåê No gender specified ‚Üí Showing BOTH genders\")\n",
    "    \n",
    "    state['detected_gender'] = final_gender\n",
    "    state['gender_source'] = gender_source\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 2: SCENARIO DETECTION\n",
    "    # ========================================================================\n",
    "    \n",
    "    # Scenario 1: IMAGE ONLY\n",
    "    if has_image and (not query or query in ['similar', 'like this', 'same', ''] or len(query.split()) <= 2):\n",
    "        state['search_mode'] = 'image_only'\n",
    "        state['search_queries'] = ['visual_search']\n",
    "        state['query_categories'] = ['similar']\n",
    "        state['intent_type'] = 'image_search'\n",
    "        state['messages'].append(f\"üéØ Image-only search mode (100% visual similarity)\")\n",
    "        state['next_agent'] = 'search_executor'\n",
    "        return state\n",
    "    \n",
    "    # Scenario 4: IMAGE + TEXT (hybrid)\n",
    "    if has_image and query and len(query.split()) > 2:\n",
    "        state['search_mode'] = 'hybrid'\n",
    "        state['messages'].append(f\"üéØ Hybrid mode: Text + Image (70% text, 30% image)\")\n",
    "    \n",
    "    # Scenario 2, 3, 5: TEXT ONLY\n",
    "    else:\n",
    "        state['search_mode'] = 'text_only'\n",
    "        state['messages'].append(f\"üéØ Text-only mode\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 3: GEMINI QUERY GENERATION WITH GENDER AWARENESS\n",
    "    # ========================================================================\n",
    "    \n",
    "    context_parts = []\n",
    "    if has_image:\n",
    "        context_parts.append(f\"User uploaded image: {image_desc}\")\n",
    "    if matched_items:\n",
    "        context_parts.append(f\"Detected items: {', '.join(matched_items[:5])}\")\n",
    "    if matched_colors:\n",
    "        context_parts.append(f\"Detected colors: {', '.join(matched_colors[:5])}\")\n",
    "    \n",
    "    context_parts.append(f\"Target gender: {final_gender.upper()} (source: {gender_source})\")\n",
    "    context_str = \"\\n\".join(context_parts)\n",
    "    \n",
    "    available_items = list(config.DYNAMIC_FASHION_ITEMS)[:40]\n",
    "    available_colors = list(config.DYNAMIC_COLORS)[:25]\n",
    "    available_genders = list(config.DYNAMIC_GENDERS)\n",
    "    \n",
    "    system_instruction = f\"\"\"You are an Expert Fashion Search Query Generator with GENDER AWARENESS.\n",
    "\n",
    "**AVAILABLE INVENTORY:**\n",
    "- Items: {', '.join(available_items)}\n",
    "- Colors: {', '.join(available_colors)}\n",
    "- Genders: {', '.join(available_genders)}\n",
    "\n",
    "**GENDER HANDLING (IMPORTANT):**\n",
    "- Target gender: {final_gender.upper()}\n",
    "- If target is \"MEN\" ‚Üí Include ONLY men's fashion queries\n",
    "- If target is \"WOMEN\" ‚Üí Include ONLY women's fashion queries\n",
    "- If target is \"BOTH\" ‚Üí Include queries for BOTH men AND women (duplicate queries for each gender)\n",
    "\n",
    "**YOUR TASK:** Generate search queries based on these scenarios:\n",
    "\n",
    "---\n",
    "\n",
    "**SCENARIO 2: TEXT ONLY - SPECIFIC ITEM**\n",
    "- Generate: 1-2 queries for that specific item\n",
    "- Examples:\n",
    "  * \"blue shirt\" + BOTH gender ‚Üí [\"men blue shirt\", \"women blue shirt\"]\n",
    "  * \"black jeans\" + MEN gender ‚Üí [\"men black jeans\"]\n",
    "  * \"red dress\" + WOMEN gender ‚Üí [\"women red dress\"]\n",
    "\n",
    "**SCENARIO 3: TEXT ONLY - RECOMMENDATION REQUEST (COMPLETE OUTFIT)**\n",
    "- Generate: Multiple queries covering ALL OUTFIT CATEGORIES\n",
    "- **REQUIRED CATEGORIES:** top, bottom, footwear, accessories, watches\n",
    "- Gender awareness: Duplicate for each gender if target is BOTH\n",
    "- **ALWAYS include watches in recommendations for complete looks**\n",
    "- Examples:\n",
    "  * \"wedding outfit\" + BOTH gender ‚Üí \n",
    "    * Top: [\"men formal shirt\", \"women formal shirt\", \"men blazer\", \"women blazer\"]\n",
    "    * Bottom: [\"men dress pants\", \"women dress pants\", \"men formal trousers\"]\n",
    "    * Footwear: [\"men formal shoes\", \"women formal shoes\", \"men oxford shoes\"]\n",
    "    * Accessories: [\"men leather belt\", \"women clutch bag\", \"men tie\"]\n",
    "    * Watches: [\"men formal watch\", \"women formal watch\", \"men dress watch\"]\n",
    "  \n",
    "  * \"party outfit\" + WOMEN gender ‚Üí\n",
    "    * Top: [\"women party dress\", \"women cocktail dress\"]\n",
    "    * Footwear: [\"women heels\", \"women party shoes\"]\n",
    "    * Accessories: [\"women clutch\", \"women jewelry\"]\n",
    "    * Watches: [\"women elegant watch\", \"women fashion watch\"]\n",
    "  \n",
    "  * \"casual outfit\" + MEN gender ‚Üí\n",
    "    * Top: [\"men casual shirt\", \"men tshirt\"]\n",
    "    * Bottom: [\"men jeans\", \"men casual pants\"]\n",
    "    * Footwear: [\"men sneakers\", \"men casual shoes\"]\n",
    "    * Accessories: [\"men casual belt\", \"men backpack\"]\n",
    "    * Watches: [\"men casual watch\", \"men sports watch\"]\n",
    "  \n",
    "  * \"office outfit\" + BOTH gender ‚Üí\n",
    "    * Top: [\"men dress shirt\", \"women blouse\", \"men blazer\", \"women blazer\"]\n",
    "    * Bottom: [\"men dress pants\", \"women dress pants\", \"women pencil skirt\"]\n",
    "    * Footwear: [\"men dress shoes\", \"women office heels\"]\n",
    "    * Accessories: [\"men leather briefcase\", \"women work bag\"]\n",
    "    * Watches: [\"men professional watch\", \"women business watch\"]\n",
    "\n",
    "**SCENARIO 4: IMAGE + TEXT - MATCHING REQUEST**\n",
    "- Examples:\n",
    "  * Text: \"black shirt\" + MEN ‚Üí [\"men black shirt\"]\n",
    "  * Text: \"black shirt\" + BOTH ‚Üí [\"men black shirt\", \"women black shirt\"]\n",
    "\n",
    "**SCENARIO 5: TEXT - ITEM FOR ITEM**\n",
    "- Examples:\n",
    "  * \"black shirt for blue pants\" + BOTH ‚Üí [\"men black shirt\", \"women black shirt\"]\n",
    "\n",
    "---\n",
    "\n",
    "**WATCH SELECTION GUIDELINES:**\n",
    "- **Formal occasions** (wedding, business, office): formal watch, dress watch, elegant watch\n",
    "- **Casual occasions** (casual day, weekend): casual watch, sports watch, fashion watch\n",
    "- **Party/Evening** (party, date night): elegant watch, fashion watch, statement watch\n",
    "- **Always gender-specific**: \"men formal watch\", \"women elegant watch\"\n",
    "\n",
    "**COLOR THEORY:**\n",
    "- Blue pairs with: white, beige, cream, grey\n",
    "- Black pairs with: white, grey, any bright color\n",
    "- Red pairs with: white, black, navy\n",
    "- Watches: Silver/steel for formal, leather bands for casual, gold for elegant\n",
    "\n",
    "**OUTPUT FORMAT - STRICT JSON:**\n",
    "\n",
    "For Scenario 2, 4, 5 (Direct/Matching):\n",
    "```json\n",
    "{{\n",
    "  \"intent\": \"direct_search\",\n",
    "  \"queries\": [\"query1\", \"query2\"],\n",
    "  \"results_per_query\": 5,\n",
    "  \"gender_aware\": true\n",
    "}}\n",
    "```\n",
    "\n",
    "For Scenario 3 (Recommendations with WATCHES):\n",
    "```json\n",
    "{{\n",
    "  \"intent\": \"outfit_recommendation\",\n",
    "  \"categories\": [\n",
    "    {{\"category\": \"top\", \"queries\": [\"men formal shirt\", \"women formal shirt\"]}},\n",
    "    {{\"category\": \"bottom\", \"queries\": [\"men dress pants\", \"women dress pants\"]}},\n",
    "    {{\"category\": \"footwear\", \"queries\": [\"men formal shoes\", \"women heels\"]}},\n",
    "    {{\"category\": \"accessories\", \"queries\": [\"men leather belt\", \"women clutch\"]}},\n",
    "    {{\"category\": \"watches\", \"queries\": [\"men formal watch\", \"women elegant watch\"]}}\n",
    "  ],\n",
    "  \"results_per_query\": 5,\n",
    "  \"gender_aware\": true\n",
    "}}\n",
    "```\n",
    "\n",
    "**CRITICAL RULES:**\n",
    "- ALWAYS include gender prefix in queries: \"men [item]\" or \"women [item]\"\n",
    "- If target gender is BOTH ‚Üí Generate queries for BOTH genders\n",
    "- If target gender is MEN or WOMEN ‚Üí Generate queries for ONLY that gender\n",
    "- **ALWAYS include \"watches\" category for outfit recommendations**\n",
    "- 2-6 words per query\n",
    "- Return ONLY valid JSON\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"Analyze this fashion search request:\n",
    "\n",
    "User Query: \"{query}\"\n",
    "\n",
    "Context:\n",
    "{context_str}\n",
    "\n",
    "Target Gender: {final_gender.upper()}\n",
    "\n",
    "Generate appropriate search queries with gender awareness. Return ONLY JSON.\"\"\"\n",
    "\n",
    "    # ========================================================================\n",
    "    # CALL GEMINI API\n",
    "    # ========================================================================\n",
    "    \n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model=MODEL,\n",
    "            contents=user_prompt,\n",
    "            config=types.GenerateContentConfig(\n",
    "                system_instruction=system_instruction,\n",
    "                temperature=0.3,\n",
    "                top_p=0.8,\n",
    "                top_k=40,\n",
    "                response_mime_type=\"application/json\"\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        response_text = response.text.strip().replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "        parsed_response = json.loads(response_text)\n",
    "        \n",
    "        intent_type = parsed_response.get('intent', 'direct_search')\n",
    "        \n",
    "        if intent_type == \"outfit_recommendation\":\n",
    "            all_queries = []\n",
    "            categories_info = []\n",
    "            \n",
    "            for cat in parsed_response.get('categories', []):\n",
    "                category_name = cat.get('category', 'items')\n",
    "                category_queries = cat.get('queries', [])\n",
    "                \n",
    "                for q in category_queries:\n",
    "                    all_queries.append(q)\n",
    "                    categories_info.append(category_name)\n",
    "            \n",
    "            state['search_queries'] = all_queries\n",
    "            state['query_categories'] = categories_info\n",
    "            state['intent_type'] = 'recommendation'\n",
    "            state['messages'].append(f\"‚úÖ Gemini: {len(all_queries)} gender-aware queries\")\n",
    "        \n",
    "        else:\n",
    "            queries = parsed_response.get('queries', [])\n",
    "            if not queries:\n",
    "                queries = [query if query else \"fashion items\"]\n",
    "            \n",
    "            state['search_queries'] = queries[:10]  # Allow more for both genders\n",
    "            state['query_categories'] = ['general'] * len(state['search_queries'])\n",
    "            state['intent_type'] = intent_type\n",
    "            state['messages'].append(f\"‚úÖ Gemini: {len(state['search_queries'])} queries\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        # ====================================================================\n",
    "        # FALLBACK: Rule-based with gender awareness\n",
    "        # ====================================================================\n",
    "        state['messages'].append(f\"‚ö†Ô∏è Gemini failed ‚Üí Rule-based fallback\")\n",
    "        \n",
    "        gender_prefixes = []\n",
    "        if final_gender == \"both\":\n",
    "            gender_prefixes = [\"men\", \"women\"]\n",
    "        elif final_gender == \"men\":\n",
    "            gender_prefixes = [\"men\"]\n",
    "        elif final_gender == \"women\":\n",
    "            gender_prefixes = [\"women\"]\n",
    "        else:\n",
    "            gender_prefixes = [\"men\", \"women\"]  # Default to both\n",
    "        \n",
    "        if any(word in query for word in ['wedding', 'party', 'office', 'recommend', 'outfit']):\n",
    "            state['search_queries'] = []\n",
    "            state['query_categories'] = []\n",
    "            for gender_prefix in gender_prefixes:\n",
    "                state['search_queries'].extend([\n",
    "                    f\"{gender_prefix} formal shirt\",\n",
    "                    f\"{gender_prefix} dress pants\",\n",
    "                    f\"{gender_prefix} formal shoes\",\n",
    "                    f\"{gender_prefix} leather belt\",\n",
    "                    f\"{gender_prefix} formal watch\"  # Added watches\n",
    "                ])\n",
    "                state['query_categories'].extend(['top', 'bottom', 'footwear', 'accessories', 'watches'])\n",
    "            state['intent_type'] = 'recommendation'\n",
    "        \n",
    "        else:\n",
    "            state['search_queries'] = [f\"{gp} {query}\" for gp in gender_prefixes]\n",
    "            state['query_categories'] = ['general'] * len(state['search_queries'])\n",
    "            state['intent_type'] = 'direct_search'\n",
    "    \n",
    "    state['debug_info'].update({\n",
    "        'search_mode': state.get('search_mode'),\n",
    "        'detected_gender': final_gender,\n",
    "        'gender_source': gender_source,\n",
    "        'gender_rule': detected_gender_rule,\n",
    "        'gender_llm': detected_gender_llm\n",
    "    })\n",
    "    \n",
    "    state['next_agent'] = 'search_executor'\n",
    "    return state\n",
    "\n",
    "# ================================================================================\n",
    "# CELL 11: FIXED SEARCH EXECUTOR WITH PROPER IMAGE SEARCH\n",
    "# ================================================================================\n",
    "\n",
    "def search_executor_agent(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    FIXED: Properly handles image-only, text-only, and hybrid searches with gender filtering\n",
    "    \"\"\"\n",
    "    search_mode = state.get('search_mode', 'text_only')\n",
    "    queries = state.get('search_queries', [])\n",
    "    categories = state.get('query_categories', [])\n",
    "    intent_type = state.get('intent_type', 'direct_search')\n",
    "    image_embedding = state.get('image_embedding')\n",
    "    detected_gender = state.get('detected_gender', 'both')\n",
    "    \n",
    "    if not queries and not image_embedding:\n",
    "        state['final_response'] = \"‚ùå No search criteria available\"\n",
    "        state['search_results_data'] = []\n",
    "        state['next_agent'] = 'end'\n",
    "        return state\n",
    "    \n",
    "    state['messages'].append(f\"üîç Search mode: {search_mode}, Gender: {detected_gender.upper()}\")\n",
    "    \n",
    "    all_grouped_results = []\n",
    "    \n",
    "    # ========================================================================\n",
    "    # IMAGE-ONLY SEARCH (100% visual similarity)\n",
    "    # ========================================================================\n",
    "    if search_mode == 'image_only' and image_embedding is not None:\n",
    "        try:\n",
    "            img_emb_normalized = image_embedding / np.linalg.norm(image_embedding)\n",
    "            emb_arr = np.array([img_emb_normalized]).astype('float32')\n",
    "            \n",
    "            distances, indices = faiss_index.search(emb_arr, 15)\n",
    "            \n",
    "            valid_items = []\n",
    "            for faiss_idx, score in zip(indices[0], distances[0]):\n",
    "                if score < 0.5:\n",
    "                    continue\n",
    "                    \n",
    "                meta = metadata_df.iloc[faiss_idx]\n",
    "                img_path = meta.get('source_path') or meta.get('thumbnail_url')\n",
    "                \n",
    "                if img_path and os.path.exists(img_path):\n",
    "                    valid_items.append({\n",
    "                        'id': int(meta['id']),\n",
    "                        'title': meta['title'],\n",
    "                        'brand': meta['brand'],\n",
    "                        'price': meta['price'],\n",
    "                        'color': meta['color'],\n",
    "                        'article_type': meta['article_type'],\n",
    "                        'snippet': meta['snippet'],\n",
    "                        'source_path': img_path,\n",
    "                        'thumbnail_url': img_path,\n",
    "                        'score': float(score),\n",
    "                        'gender': meta.get('gender', 'N/A')\n",
    "                    })\n",
    "                    \n",
    "                    if len(valid_items) >= 5:\n",
    "                        break\n",
    "            \n",
    "            all_grouped_results.append({\n",
    "                \"query_number\": 1,\n",
    "                \"query_text\": \"Similar items (visual search)\",\n",
    "                \"category\": \"similar\",\n",
    "                \"items\": valid_items,\n",
    "                \"item_count\": len(valid_items)\n",
    "            })\n",
    "            \n",
    "            state['messages'].append(f\"  ‚úì Visual search: {len(valid_items)} similar items\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            state['messages'].append(f\"  ‚ö†Ô∏è Image search failed: {str(e)[:50]}\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # TEXT-ONLY or HYBRID SEARCH WITH GENDER FILTERING\n",
    "    # ========================================================================\n",
    "    else:\n",
    "        for idx, query_text in enumerate(queries):\n",
    "            category = categories[idx] if idx < len(categories) else 'general'\n",
    "            \n",
    "            try:\n",
    "                # Get text embedding\n",
    "                text_emb = get_text_embedding(query_text)\n",
    "                text_emb = text_emb / np.linalg.norm(text_emb)\n",
    "                \n",
    "                # HYBRID: Combine text and image embeddings\n",
    "                if search_mode == 'hybrid' and image_embedding is not None:\n",
    "                    img_emb_normalized = image_embedding / np.linalg.norm(image_embedding)\n",
    "                    combined_emb = (config.TEXT_WEIGHT * text_emb + \n",
    "                                   config.IMAGE_WEIGHT * img_emb_normalized)\n",
    "                    combined_emb = combined_emb / np.linalg.norm(combined_emb)\n",
    "                    search_emb = combined_emb\n",
    "                else:\n",
    "                    search_emb = text_emb\n",
    "                \n",
    "                # Search FAISS\n",
    "                emb_arr = np.array([search_emb]).astype('float32')\n",
    "                distances, indices = faiss_index.search(emb_arr, 20)  # Get more for filtering\n",
    "                \n",
    "                # Collect valid results with gender filtering\n",
    "                valid_items = []\n",
    "                for faiss_idx, score in zip(indices[0], distances[0]):\n",
    "                    meta = metadata_df.iloc[faiss_idx]\n",
    "                    item_gender = str(meta.get('gender', '')).lower()\n",
    "                    \n",
    "                    # Gender filtering logic\n",
    "                    if detected_gender == \"men\" and item_gender not in [\"men\", \"male\", \"boys\"]:\n",
    "                        continue\n",
    "                    elif detected_gender == \"women\" and item_gender not in [\"women\", \"female\", \"girls\"]:\n",
    "                        continue\n",
    "                    # If detected_gender == \"both\", include all items\n",
    "                    \n",
    "                    img_path = meta.get('source_path') or meta.get('thumbnail_url')\n",
    "                    \n",
    "                    if img_path and os.path.exists(img_path):\n",
    "                        valid_items.append({\n",
    "                            'id': int(meta['id']),\n",
    "                            'title': meta['title'],\n",
    "                            'brand': meta['brand'],\n",
    "                            'price': meta['price'],\n",
    "                            'color': meta['color'],\n",
    "                            'article_type': meta['article_type'],\n",
    "                            'snippet': meta['snippet'],\n",
    "                            'source_path': img_path,\n",
    "                            'thumbnail_url': img_path,\n",
    "                            'score': float(score),\n",
    "                            'gender': item_gender\n",
    "                        })\n",
    "                        \n",
    "                        if len(valid_items) >= 5:\n",
    "                            break\n",
    "                \n",
    "                all_grouped_results.append({\n",
    "                    \"query_number\": idx + 1,\n",
    "                    \"query_text\": query_text,\n",
    "                    \"category\": category,\n",
    "                    \"items\": valid_items,\n",
    "                    \"item_count\": len(valid_items),\n",
    "                    \"gender_filter\": detected_gender\n",
    "                })\n",
    "                \n",
    "                mode_str = \"hybrid\" if search_mode == 'hybrid' else \"text\"\n",
    "                state['messages'].append(f\"  ‚úì Q{idx+1} ({mode_str}) [{category}]: '{query_text}' ‚Üí {len(valid_items)} items ({detected_gender})\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                state['messages'].append(f\"  ‚ö†Ô∏è Query {idx+1} failed: {str(e)[:50]}\")\n",
    "                all_grouped_results.append({\n",
    "                    \"query_number\": idx + 1,\n",
    "                    \"query_text\": query_text,\n",
    "                    \"category\": category,\n",
    "                    \"items\": [],\n",
    "                    \"item_count\": 0,\n",
    "                    \"gender_filter\": detected_gender\n",
    "                })\n",
    "    \n",
    "    # ========================================================================\n",
    "    # BUILD FINAL RESPONSE WITH GENDER INFO\n",
    "    # ========================================================================\n",
    "    \n",
    "    total_items = sum(g['item_count'] for g in all_grouped_results)\n",
    "    state['search_results_data'] = all_grouped_results\n",
    "    \n",
    "    gender_info = \"\"\n",
    "    if detected_gender == \"men\":\n",
    "        gender_info = \"\\nüöπ **Showing: Men's Fashion Only**\"\n",
    "    elif detected_gender == \"women\":\n",
    "        gender_info = \"\\nüö∫ **Showing: Women's Fashion Only**\"\n",
    "    elif detected_gender == \"both\":\n",
    "        gender_info = \"\\n‚öß **Showing: Both Men's and Women's Fashion**\"\n",
    "    \n",
    "    if search_mode == 'image_only':\n",
    "        state['final_response'] = f\"\"\"üì∏ **Similar Fashion Items**\n",
    "\n",
    "**Found {total_items} visually similar items**{gender_info}\n",
    "\n",
    "---\n",
    "\n",
    "**üí° Tip:** These items match the style, color, and type of your uploaded image!\"\"\"\n",
    "    \n",
    "    elif intent_type == 'recommendation':\n",
    "        state['final_response'] = f\"\"\"‚ú® **Complete Outfit Recommendation**\n",
    "\n",
    "**{len(queries)} Items Curated for Your Occasion**\n",
    "**{total_items} Total Products Found**{gender_info}\n",
    "\n",
    "---\n",
    "\n",
    "**üí° Styling Tip:** Mix and match these pieces for a complete look!\"\"\"\n",
    "        \n",
    "        categories_dict = {}\n",
    "        category_emojis = {\n",
    "            'top': 'üëï',\n",
    "            'bottom': 'üëñ',\n",
    "            'footwear': 'üëü',\n",
    "            'accessories': 'üëú',\n",
    "            'watches': '‚åö'\n",
    "        }\n",
    "        \n",
    "        for group in all_grouped_results:\n",
    "            cat = group['category']\n",
    "            if cat not in categories_dict:\n",
    "                categories_dict[cat] = []\n",
    "            categories_dict[cat].append(group)\n",
    "        \n",
    "        # Display in logical order\n",
    "        category_order = ['top', 'bottom', 'footwear', 'accessories', 'watches']\n",
    "        \n",
    "        for cat_name in category_order:\n",
    "            if cat_name in categories_dict:\n",
    "                cat_groups = categories_dict[cat_name]\n",
    "                total_cat_items = sum(g['item_count'] for g in cat_groups)\n",
    "                emoji = category_emojis.get(cat_name, 'üì¶')\n",
    "                state['final_response'] += f\"\\n\\n**{emoji} {cat_name.upper()}** ({total_cat_items} items)\"\n",
    "                for group in cat_groups:\n",
    "                    if group['item_count'] > 0:\n",
    "                        state['final_response'] += f\"\\n  ‚îî‚îÄ {group['query_text']}: {group['item_count']} options\"\n",
    "    \n",
    "    elif search_mode == 'hybrid':\n",
    "        state['final_response'] = f\"\"\"üé® **Smart Matching Results**\n",
    "\n",
    "**These items match your image and text!**\n",
    "**{total_items} Total Matches**{gender_info}\n",
    "\n",
    "---\n",
    "\n",
    "**üí° Tip:** Results prioritize your text (70%) with visual hints.\"\"\"\n",
    "        \n",
    "        for group in all_grouped_results:\n",
    "            if group['item_count'] > 0:\n",
    "                state['final_response'] += f\"\\n\\n**{group['query_text']}**\"\n",
    "                state['final_response'] += f\"\\n‚îî‚îÄ {group['item_count']} items\"\n",
    "    \n",
    "    else:\n",
    "        state['final_response'] = f\"\"\"üîç **Search Results**\n",
    "\n",
    "**Found {total_items} items**{gender_info}\n",
    "\n",
    "---\"\"\"\n",
    "        \n",
    "        for group in all_grouped_results:\n",
    "            if group['item_count'] > 0:\n",
    "                state['final_response'] += f\"\\n\\n**{group['query_text']}**\"\n",
    "                state['final_response'] += f\"\\n‚îî‚îÄ {group['item_count']} items\"\n",
    "    \n",
    "    state['next_agent'] = 'end'\n",
    "    state['messages'].append(f\"‚úÖ Complete: {total_items} items, mode={search_mode}, gender={detected_gender}\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "# ================================================================================\n",
    "# CELL 12: BUILD WORKFLOW\n",
    "# ================================================================================\n",
    "\n",
    "def route_agent(state: AgentState) -> str:\n",
    "    return state.get('next_agent', 'end')\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"image_fashion_validator\", image_fashion_validator_agent)\n",
    "workflow.add_node(\"image_to_description\", image_to_description_agent)\n",
    "workflow.add_node(\"non_relevant_image_agent\", non_relevant_image_agent)\n",
    "workflow.add_node(\"intent_classifier\", intent_classifier_agent)\n",
    "workflow.add_node(\"welcome_agent\", welcome_agent)\n",
    "workflow.add_node(\"non_relevant_agent\", non_relevant_agent)\n",
    "workflow.add_node(\"smart_query_understanding\", smart_query_understanding_agent)\n",
    "workflow.add_node(\"search_executor\", search_executor_agent)\n",
    "\n",
    "workflow.set_entry_point(\"image_fashion_validator\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"image_fashion_validator\", \n",
    "    route_agent, \n",
    "    {\n",
    "        \"image_to_description\": \"image_to_description\",\n",
    "        \"non_relevant_image_agent\": \"non_relevant_image_agent\", \n",
    "        \"intent_classifier\": \"intent_classifier\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\"non_relevant_image_agent\", route_agent, {\"end\": END})\n",
    "workflow.add_conditional_edges(\"image_to_description\", route_agent, {\"intent_classifier\": \"intent_classifier\", \"end\": END})\n",
    "workflow.add_conditional_edges(\n",
    "    \"intent_classifier\",\n",
    "    route_agent, \n",
    "    {\n",
    "        \"welcome_agent\": \"welcome_agent\",\n",
    "        \"non_relevant_agent\": \"non_relevant_agent\", \n",
    "        \"fashion_classifier\": \"smart_query_understanding\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "workflow.add_conditional_edges(\"welcome_agent\", route_agent, {\"end\": END})\n",
    "workflow.add_conditional_edges(\"non_relevant_agent\", route_agent, {\"end\": END})\n",
    "workflow.add_edge(\"smart_query_understanding\", \"search_executor\")\n",
    "workflow.add_edge(\"search_executor\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "print(\"‚úÖ Workflow ready with FIXED image search\")\n",
    "\n",
    "# ================================================================================\n",
    "# CELL 13: BUILD FAISS INDEX\n",
    "# ================================================================================\n",
    "\n",
    "def build_faiss_index(df_subset: pd.DataFrame) -> tuple:\n",
    "    print(f\"\\nüî® Building FAISS index...\")\n",
    "    embeddings, metadata = [], []\n",
    "    \n",
    "    for idx, row in df_subset.head(config.FAISS_MAX_ITEMS).iterrows():\n",
    "        try:\n",
    "            if not row['image_path'] or not os.path.exists(row['image_path']):\n",
    "                continue\n",
    "            img = Image.open(row['image_path']).convert('RGB')\n",
    "            emb = get_image_embedding(img)\n",
    "            embeddings.append(emb)\n",
    "            metadata.append({\n",
    "                'id': len(metadata), 'image_id': row.get('id', idx),\n",
    "                'title': f\"{row.get('articleType', 'Item')} - {row.get('baseColour', 'Color')}\",\n",
    "                'brand': row.get('brandName', 'Brand'), 'price': row.get('price', 'N/A'),\n",
    "                'thumbnail_url': row['image_path'], 'source_path': row['image_path'],\n",
    "                'snippet': f\"{row.get('gender', '')} {row.get('articleType', '')} in {row.get('baseColour', '')}\".strip(),\n",
    "                'gender': row.get('gender', 'N/A'), 'article_type': row.get('articleType', 'N/A'),\n",
    "                'color': row.get('baseColour', 'N/A')\n",
    "            })\n",
    "            if len(embeddings) % config.INDEX_BATCH_SIZE == 0:\n",
    "                print(f\"  ‚úì {len(embeddings)} items\")\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    emb_array = np.array(embeddings).astype('float32')\n",
    "    index = faiss.IndexFlatIP(emb_array.shape[1])\n",
    "    index.add(emb_array)\n",
    "    meta_df = pd.DataFrame(metadata)\n",
    "    print(f\"‚úÖ Index: {index.ntotal} items, {emb_array.shape[1]}D\")\n",
    "    return index, meta_df\n",
    "\n",
    "faiss_index, metadata_df = build_faiss_index(df_with_images)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================================\n",
    "# CELL 14: GRADIO INTERFACE\n",
    "# ================================================================================\n",
    "\n",
    "def process_query(user_text, user_image):\n",
    "    try:\n",
    "        img_path = None\n",
    "        if user_image:\n",
    "            user_image.save(\"temp_img.jpg\")\n",
    "            img_path = \"temp_img.jpg\"\n",
    "        \n",
    "        state = {\n",
    "            \"user_input\": user_text or \"\",\n",
    "            \"image_input\": img_path,\n",
    "            \"image_embedding\": None,\n",
    "            \"is_fashion_image\": None,\n",
    "            \"image_validation_reason\": None,\n",
    "            \"image_description\": None,\n",
    "            \"text_query\": None,\n",
    "            \"intent\": None,\n",
    "            \"intent_class\": None,\n",
    "            \"messages\": [],\n",
    "            \"final_response\": None,\n",
    "            \"next_agent\": None,\n",
    "            \"debug_info\": {},\n",
    "            \"search_queries\": [],\n",
    "            \"search_results_data\": [],\n",
    "            \"query_categories\": [],\n",
    "            \"intent_type\": None,\n",
    "            \"search_mode\": None,\n",
    "            \"detected_gender\": None,\n",
    "            \"gender_source\": None\n",
    "        }\n",
    "        \n",
    "        result = app.invoke(state)\n",
    "        \n",
    "        flow = \"\\n\".join([f\"‚Ä¢ {m}\" for m in result['messages']])\n",
    "        response = f\"### ü§ñ Agent Flow:\\n{flow}\\n\\n### üí¨ Result:\\n{result.get('final_response', 'No response')}\"\n",
    "        \n",
    "        gallery_items = []\n",
    "        search_data = result.get('search_results_data', [])\n",
    "        \n",
    "        if search_data:\n",
    "            response += f\"\\n\\n---\\n### üñºÔ∏è Search Results:\"\n",
    "            \n",
    "            for group in search_data:\n",
    "                query_num = group.get('query_number', '?')\n",
    "                query_text = group.get('query_text', 'Unknown')\n",
    "                category = group.get('category', 'general')\n",
    "                items = group.get('items', [])\n",
    "                \n",
    "                response += f\"\\n\\n**Query {query_num} [{category}]: {query_text}** ({len(items)} items)\"\n",
    "                \n",
    "                for item in items:\n",
    "                    img_path = item.get('source_path') or item.get('thumbnail_url')\n",
    "                    if img_path and os.path.exists(img_path):\n",
    "                        try:\n",
    "                            caption = (\n",
    "                                f\"üîç {query_text}\\n\"\n",
    "                                f\"üì¶ {category}\\n\"\n",
    "                                f\"üëî {item.get('title', 'Item')}\\n\"\n",
    "                                f\"üè∑Ô∏è {item.get('brand', 'N/A')} | \"\n",
    "                                f\"üí∞ ‚Çπ{item.get('price', 'N/A')}\\n\"\n",
    "                                f\"üìä Match: {item.get('score', 0):.3f}\"\n",
    "                            )\n",
    "                            gallery_items.append((img_path, caption))\n",
    "                        except:\n",
    "                            continue\n",
    "        \n",
    "        if result.get('search_mode'):\n",
    "            response += f\"\\n\\n---\\n### ‚öôÔ∏è Search Configuration:\"\n",
    "            response += f\"\\n‚Ä¢ **Search Mode:** {result['search_mode']}\"\n",
    "            \n",
    "            if result.get('detected_gender'):\n",
    "                gender_emoji = {\n",
    "                    'men': 'üöπ MEN',\n",
    "                    'women': 'üö∫ WOMEN',\n",
    "                    'both': '‚öß BOTH (Men & Women)'\n",
    "                }.get(result['detected_gender'], result['detected_gender'])\n",
    "                \n",
    "                response += f\"\\n‚Ä¢ **Target Gender:** {gender_emoji}\"\n",
    "                \n",
    "                gender_source = result.get('gender_source', 'unknown')\n",
    "                if gender_source == 'both_agree':\n",
    "                    response += \" ‚úÖ (Rule + LLM agree)\"\n",
    "                elif gender_source == 'rule_only':\n",
    "                    response += \" üìè (Rule-based detection)\"\n",
    "                elif gender_source == 'llm_only':\n",
    "                    response += \" ü§ñ (LLM detection)\"\n",
    "                elif gender_source == 'rule_priority':\n",
    "                    response += \" ‚öñÔ∏è (Rule priority over LLM)\"\n",
    "                elif gender_source == 'default_both':\n",
    "                    response += \" üåê (Default: no gender specified)\"\n",
    "        \n",
    "        if result.get('debug_info'):\n",
    "            debug = result['debug_info']\n",
    "            response += f\"\\n\\n**Gender Detection Details:**\"\n",
    "            if debug.get('gender_rule'):\n",
    "                response += f\"\\n‚Ä¢ Rule-based: {debug['gender_rule'].upper()}\"\n",
    "            else:\n",
    "                response += f\"\\n‚Ä¢ Rule-based: None\"\n",
    "            \n",
    "            if debug.get('gender_llm'):\n",
    "                response += f\"\\n‚Ä¢ LLM detection: {debug['gender_llm'].upper()}\"\n",
    "            else:\n",
    "                response += f\"\\n‚Ä¢ LLM detection: Not used\"\n",
    "            \n",
    "            response += f\"\\n‚Ä¢ Final decision: {debug.get('detected_gender', 'N/A').upper()}\"\n",
    "            response += f\"\\n‚Ä¢ Vocabulary: {debug.get('vocabulary_size', 'N/A')} items\"\n",
    "        \n",
    "        return response, gallery_items\n",
    "        \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        return f\"### ‚ùå Error:\\n{str(e)}\\n\\n```\\n{traceback.format_exc()}\\n```\", []\n",
    "\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # üëó Smart Fashion AI - GENDER-AWARE SEARCH\n",
    "    \n",
    "    **‚ú® Intelligent Gender Detection:**\n",
    "    ‚Ä¢ üìè **Rule-based:** Detects keywords (men, women, male, female, etc.)\n",
    "    ‚Ä¢ ü§ñ **LLM-powered:** Gemini analyzes context for gender\n",
    "    ‚Ä¢ üéØ **Smart defaults:** No gender specified ‚Üí Shows BOTH genders\n",
    "    \n",
    "    **üîç Search Modes:**\n",
    "    ‚Ä¢ üì∏ Image-only: 100% visual matching\n",
    "    ‚Ä¢ üí¨ Text-only: 100% text search\n",
    "    ‚Ä¢ üé® Hybrid: 70% text + 30% image\n",
    "    \"\"\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            text_in = gr.Textbox(\n",
    "                label=\"üí¨ Your Fashion Query\",\n",
    "                placeholder=\"Try: 'wedding outfit for men', 'blue jeans', 'party dress for women'\",\n",
    "                lines=4\n",
    "            )\n",
    "            img_in = gr.Image(label=\"üì∏ Upload Fashion Image (Optional)\", type=\"pil\")\n",
    "            btn = gr.Button(\"üöÄ Search Fashion Items\", variant=\"primary\", size=\"lg\")\n",
    "            \n",
    "            gr.Markdown(\"\"\"\n",
    "            ### üí° Gender-Aware Examples:\n",
    "            \n",
    "            **üöπ Men's Fashion:**\n",
    "            ‚Ä¢ \"wedding outfit for men\" ‚Üí Men's formal wear\n",
    "            ‚Ä¢ \"men blue jeans\" ‚Üí Men's jeans only\n",
    "            ‚Ä¢ \"casual shirt for him\" ‚Üí Men's shirts\n",
    "            \n",
    "            **üö∫ Women's Fashion:**\n",
    "            ‚Ä¢ \"party dress for women\" ‚Üí Women's dresses\n",
    "            ‚Ä¢ \"women black heels\" ‚Üí Women's shoes\n",
    "            ‚Ä¢ \"outfit for her wedding\" ‚Üí Women's formal\n",
    "            \n",
    "            **‚öß Both Genders:**\n",
    "            ‚Ä¢ \"wedding outfit\" ‚Üí Both men & women\n",
    "            ‚Ä¢ \"blue jeans\" ‚Üí Both men & women\n",
    "            ‚Ä¢ \"casual summer look\" ‚Üí Both genders\n",
    "            \n",
    "            **üì∏ Image Search:**\n",
    "            ‚Ä¢ Upload image only ‚Üí Visual similarity (all genders)\n",
    "            ‚Ä¢ Upload + text ‚Üí Smart hybrid search\n",
    "            \n",
    "            ---\n",
    "            \n",
    "            **üéØ How Gender Detection Works:**\n",
    "            \n",
    "            1Ô∏è‚É£ **Rule-based Detection (Fast):**\n",
    "               ‚Ä¢ Scans for keywords: men, women, male, female, his, her, etc.\n",
    "               ‚Ä¢ Instant detection for explicit mentions\n",
    "            \n",
    "            2Ô∏è‚É£ **LLM Detection (Smart):**\n",
    "               ‚Ä¢ Gemini analyzes context and intent\n",
    "               ‚Ä¢ Handles implicit gender references\n",
    "               ‚Ä¢ Activated when rules are unclear\n",
    "            \n",
    "            3Ô∏è‚É£ **Smart Defaults:**\n",
    "               ‚Ä¢ No gender mentioned ‚Üí BOTH genders shown\n",
    "               ‚Ä¢ Equal representation for all users\n",
    "            \n",
    "            **üí° Status indicators show how gender was detected:**\n",
    "            ‚Ä¢ ‚úÖ Both agree (Rule + LLM)\n",
    "            ‚Ä¢ üìè Rule-based only\n",
    "            ‚Ä¢ ü§ñ LLM only\n",
    "            ‚Ä¢ ‚öñÔ∏è Rule priority\n",
    "            ‚Ä¢ üåê Default (both genders)\n",
    "            \"\"\")\n",
    "        \n",
    "        with gr.Column(scale=2):\n",
    "            with gr.Tabs():\n",
    "                with gr.Tab(\"ü§ñ AI Response\"):\n",
    "                    agent_out = gr.Markdown()\n",
    "                \n",
    "                with gr.Tab(\"üñºÔ∏è Fashion Results\"):\n",
    "                    gallery = gr.Gallery(\n",
    "                        label=\"Search Results\",\n",
    "                        columns=3,\n",
    "                        height=\"700px\",\n",
    "                        object_fit=\"contain\"\n",
    "                    )\n",
    "    \n",
    "    gr.Examples([\n",
    "        [\"wedding outfit for men\", None],\n",
    "        [\"party dress for women\", None],\n",
    "        [\"blue jeans\", None],  # Both genders\n",
    "        [\"wedding outfit\", None],  # Both genders\n",
    "        [\"casual shirt for him\", None],  # Men\n",
    "        [\"black heels for her\", None],  # Women\n",
    "        [\"\", None]  # Image upload\n",
    "    ], inputs=[text_in, img_in], label=\"üéØ Try These Gender-Aware Examples\")\n",
    "    \n",
    "    btn.click(process_query, [text_in, img_in], [agent_out, gallery])\n",
    "\n",
    "# ================================================================================\n",
    "# CELL 15: LAUNCH\n",
    "# ================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üöÄ LAUNCHING GENDER-AWARE FASHION AI SYSTEM...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    demo.launch(\n",
    "        share=config.GRADIO_SHARE,\n",
    "        debug=config.GRADIO_DEBUG,\n",
    "        server_port=config.GRADIO_PORT,\n",
    "        server_name=\"0.0.0.0\",\n",
    "        show_error=True,\n",
    "        allowed_paths=[config.IMAGES_PATH]\n",
    "    )\n",
    "    \n",
    "    print(f\"\"\"\n",
    "{'='*80}\n",
    "‚úÖ GENDER-AWARE FASHION AI SYSTEM - READY\n",
    "{'='*80}\n",
    "\n",
    "üìä System Status:\n",
    "   ‚Ä¢ FAISS Index: {faiss_index.ntotal:,} items\n",
    "   ‚Ä¢ Vocabulary: {len(config.DYNAMIC_FASHION_ITEMS)} items, {len(config.DYNAMIC_COLORS)} colors\n",
    "   ‚Ä¢ Available Genders: {', '.join(config.DYNAMIC_GENDERS)}\n",
    "\n",
    "üéØ GENDER DETECTION FEATURES:\n",
    "   \n",
    "   1Ô∏è‚É£ Rule-Based Detection (Fast & Explicit):\n",
    "      ‚Ä¢ Keywords: men, women, male, female, boy, girl, his, her, he, she\n",
    "      ‚Ä¢ Instant detection for clear gender mentions\n",
    "      ‚Ä¢ Example: \"men blue jeans\" ‚Üí Detects MEN instantly\n",
    "   \n",
    "   2Ô∏è‚É£ LLM Detection (Smart & Context-Aware):\n",
    "      ‚Ä¢ Powered by: {MODEL}\n",
    "      ‚Ä¢ Analyzes implicit gender references\n",
    "      ‚Ä¢ Handles complex queries\n",
    "      ‚Ä¢ Example: \"outfit for him\" ‚Üí LLM detects MALE context\n",
    "   \n",
    "   3Ô∏è‚É£ Hybrid Approach (Best of Both):\n",
    "      ‚Ä¢ Rule-based runs first (fast)\n",
    "      ‚Ä¢ LLM validates if needed (smart)\n",
    "      ‚Ä¢ Both agree ‚Üí Highest confidence ‚úÖ\n",
    "      ‚Ä¢ Conflict ‚Üí Rule-based takes priority ‚öñÔ∏è\n",
    "   \n",
    "   4Ô∏è‚É£ Smart Defaults:\n",
    "      ‚Ä¢ No gender mentioned ‚Üí BOTH genders shown üåê\n",
    "      ‚Ä¢ Ensures equal representation\n",
    "      ‚Ä¢ Example: \"blue jeans\" ‚Üí Shows men's AND women's jeans\n",
    "\n",
    "üîç Search Modes:\n",
    "   ‚Ä¢ Image-only: 100% visual similarity\n",
    "   ‚Ä¢ Text-only: 100% text matching (gender-filtered)\n",
    "   ‚Ä¢ Hybrid: 70% text + 30% image (gender-filtered)\n",
    "\n",
    "üìà Gender Detection Status Indicators:\n",
    "   ‚Ä¢ ‚úÖ Both agree - Rule + LLM confirm same gender\n",
    "   ‚Ä¢ üìè Rule-based only - Explicit keywords detected\n",
    "   ‚Ä¢ ü§ñ LLM only - Context-based detection\n",
    "   ‚Ä¢ ‚öñÔ∏è Rule priority - Rules override LLM in conflicts\n",
    "   ‚Ä¢ üåê Default both - No gender specified\n",
    "\n",
    "üí° Example Queries:\n",
    "   \n",
    "   Complete Outfits (with watches):\n",
    "   ‚Ä¢ \"wedding outfit for men\" ‚Üí üëï Shirt + üëñ Pants + üëü Shoes + üëú Belt + ‚åö Watch\n",
    "   ‚Ä¢ \"party dress for women\" ‚Üí üëó Dress + üë† Heels + üíç Accessories + ‚åö Watch\n",
    "   ‚Ä¢ \"office outfit\" ‚Üí Both genders, all categories including watches\n",
    "   \n",
    "   Explicit Gender:\n",
    "   ‚Ä¢ \"men casual watch\" ‚Üí üöπ Men's watches only\n",
    "   ‚Ä¢ \"women elegant watch\" ‚Üí üö∫ Women's watches only\n",
    "   \n",
    "   Implicit Gender:\n",
    "   ‚Ä¢ \"casual shirt for him\" ‚Üí üöπ LLM detects male\n",
    "   ‚Ä¢ \"outfit for her party\" ‚Üí üö∫ LLM detects female (includes watch)\n",
    "   \n",
    "   No Gender (Default Both):\n",
    "   ‚Ä¢ \"blue jeans\" ‚Üí ‚öß Both men & women\n",
    "   ‚Ä¢ \"wedding outfit\" ‚Üí ‚öß Complete outfits for both + watches\n",
    "   ‚Ä¢ \"black shoes\" ‚Üí ‚öß Both men & women\n",
    "\n",
    "‚åö WATCH CATEGORIES NOW INCLUDED:\n",
    "   ‚Ä¢ Formal occasions ‚Üí Dress watches, formal watches\n",
    "   ‚Ä¢ Casual occasions ‚Üí Casual watches, sports watches\n",
    "   ‚Ä¢ Party/Evening ‚Üí Elegant watches, fashion watches\n",
    "   ‚Ä¢ Office/Business ‚Üí Professional watches, business watches\n",
    "\n",
    "üåê Interface: http://localhost:{config.GRADIO_PORT}\n",
    "\n",
    "{'='*80}\n",
    "‚ú® KEY IMPROVEMENTS:\n",
    "{'='*80}\n",
    "1. ‚úÖ Gender detection: Rule-based + LLM hybrid\n",
    "2. ‚úÖ Smart defaults: No gender = show both\n",
    "3. ‚úÖ Gender filtering: Results filtered by detected gender\n",
    "4. ‚úÖ Transparent indicators: Shows how gender was detected\n",
    "5. ‚úÖ Equal representation: Both genders by default\n",
    "6. ‚úÖ Context-aware: LLM handles implicit references\n",
    "7. ‚úÖ Fast detection: Rule-based for explicit mentions\n",
    "8. ‚úÖ WATCHES INCLUDED: All outfit recommendations now include watches ‚åö\n",
    "   ‚Ä¢ Formal watches for weddings/business\n",
    "   ‚Ä¢ Casual watches for everyday wear\n",
    "   ‚Ä¢ Elegant watches for parties/evenings\n",
    "   ‚Ä¢ Sports watches for casual outfits\n",
    "\n",
    "{'='*80}\n",
    "\"\"\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå LAUNCH FAILED: {e}\")\n",
    "    import traceback\n",
    "    print(traceback.format_exc())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 175990,
     "sourceId": 396802,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
